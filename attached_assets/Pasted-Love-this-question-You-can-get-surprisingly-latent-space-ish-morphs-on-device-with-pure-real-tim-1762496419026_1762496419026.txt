Love this question. You can get surprisingly “latent-space-ish” morphs on-device with pure, real-time WebGL by combining a few classic GPU tricks: multiscale warping, feature-aware guidance, palette/texture interpolation, and gentle temporal feedback. Below is a practical blueprint that feels tasteful and “magical” rather than just crossfades/ripples—no GANs, just shaders and ping-pong FBOs.

# A tasteful, real-time “latent-space” pipeline (WebGL/WebGL2)

## 0) Inputs

Two images/textures: `A` and `B`. A normalized progress parameter `t∈[0,1]`. All steps run in small, cheap fragment passes with ping-pong textures; stay at 720p or do ½ res with a final upscale.

---

## 1) Multiband foundation (Laplacian pyramid)

**Why:** Latent morphs feel coherent because coarse structure changes separately from fine texture. Emulate that with a 3–5 level Gaussian/Laplacian pyramid.

**How (GPU):**

* Build mip chains (`textureLod`) or explicit Gaussian blurs for `A` and `B`.
* Laplacian level `Lk = Gk − upsample(Gk+1)`.
* Interpolate **each band** with different easing:

  * Coarse bands: slower, sigmoid easing (retain scene layout longer).
  * Fine bands: faster (textures/brushwork “arrive” earlier).
* Reconstruct at the end: sum of blended Laplacians + blended coarsest base.

This alone beats a straight crossfade.

---

## 2) Feature-aware guidance (edges, corners, saliency)

**Why:** Latent models “know” what’s important. You can emulate priority with cheap detectors.

**How (GPU):**

* **Edges:** Sobel/Scharr → magnitude/orientation maps `EA, EB`.
* **Corners/Saliency:** Harris or simple variance/LoG heatmap (a single pass).
* Build **SDFs** (signed distance fields) from binarized edges (jump-flooding is great on GPU).
* Produce a **guidance mask** `M` that increases blending speed around matched structure:

  * `M = smoothstep(τ0, τ1, min(SDFA, SDFB))` (closer to edges → higher weight).
* Use guidance to mix:

  * Where both images have structure, **warp** A toward B (see §3).
  * Where only one has structure, prefer that image’s band at that scale.
* Also keep an **orientation field** (unit vectors from edge orientation) for directional warps.

---

## 3) Motion-compensated warp (flow-ish without ML)

**Why:** Morphing should “move” content, not just fade.

**Cheap, robust approach (coarse-to-fine grid TPS-ish):**

1. Downsample A/B to very low res (e.g., 64×64).
2. Per cell, compute a **phase correlation** or just pick the **max NCC** offset in a tiny window (3×3 or 5×5) using a few dot products—very fast at low res.
3. You get a coarse displacement field `V0`. Smooth it with a few Jacobi blur passes.
4. **Upsample** `V0` level by level to full res; at each level, refine with one or two extra correlation passes (still tiny windows).
5. Constrain/steer with your **edge orientation**: project displacement onto local edge tangents to avoid shearing across strong lines.

Now advect A toward B:

```glsl
vec2 uvA = v_uv - mix(vec2(0.0), V(uv), t);  // push A forward
vec3 Aw = texture(A, uvA).rgb;
```

Do the symmetric thing for B (or just push A forward and crossfade B in multiband).

**Tasteful tweak:** attenuate `V` in smooth areas (to avoid “melting”), strengthen near edges (from §2 masks).

---

## 4) Color space / palette interpolation (perceptual)

**Why:** Latent morphs travel through a color manifold. Avoid straight RGB lerps.

**How:**

* Convert per-pixel to **OKLab** (or use a 3D LUT). Interpolate there, then back to RGB.
* Or compute **global color stats per pyramid level** (mean/variance in OKLab) and match A→B over time (Reinhard-style color transfer). Apply a gentle, low-frequency time curve so color mood changes “glide.”

---

## 5) Procedural detail synthesis (the “magic”)

Latent morphs invent small details. You can fake that tastefully:

* **Audio-reactive/calm LFOs** feed **curl noise** vector fields that are **aligned** to edge tangents:

  * Generate 2D curl noise `C(uv, t)` (single octave is enough).
  * Mix into the flow field only on high-frequency Laplacian bands to animate micro-texture:
    `V_detail = k * C(uv, t) * (edge_strength)`.
* **Reaction–diffusion glaze:** one tiny Gray–Scott step on a quarter-res buffer, color-mapped and added at **very** low opacity to mid bands → subtle living texture.
* **Palette cycling** of a **256-entry LUT** tied to `t`, but clamp amplitude so it never screams.

---

## 6) Temporal coherence (feedback, but gentle)

GANs produce temporal consistency; you can mimic it via a light feedback pass:

* Keep a prev frame `P`. After reconstruction, blend:

  ```glsl
  final = mix(cur, P, 0.06 * (1.0 - M_sharp)); // less feedback near sharp edges
  ```
* Also apply a tiny **temporal median** (3-tap along time) at ½ res to kill shimmer in high bands.

---

## 7) Compositing choreography (make it feel intentional)

* Use **staged easing**:

  * `t_coarse = smoothstep(0.05, 0.95, t)`
  * `t_fine   = smoothstep(0.30, 0.80, t)`
  * `t_color  = smoothstep(0.15, 0.90, t)`
* Cross-fade **structure late, texture early** → reads like “shape morph,” not dissolve.
* Add **beat- or cue-driven** micro-events: brief increases in flow magnitude, momentary palette warmth, or a 1-frame directional “breath.”

---

# Pass graph (all real-time friendly)

1. **Pyramids:** build `GA, GB` (mips) → compute Laplacians `LAk, LBk`.
2. **Features:** edges/LoG → SDFs → guidance masks & orientations.
3. **Coarse flow:** low-res NCC/phase corr → smooth → upsample/refine → full-res `V`.
4. **Warp A:** `Aw = sample(A, uv - t * V)`. Optionally warp B backward for symmetric morph.
5. **Band blending:** for each level `k`, `Lk = mix(LAk_warped, LBk, t_k)` with guidance weights.
6. **Color manifold:** OKLab LUT / stats transfer per level, lerp with `t_color`.
7. **Procedural detail:** add curl-noise micro-advection to high bands; optional low-res RD glaze.
8. **Reconstruct:** sum bands + base.
9. **Temporal:** light feedback + anti-shimmer.
10. **Output.**

On a laptop iGPU, this runs at 30–60 FPS at 720p if you keep the NCC window tiny and levels ~4.

---

# Minimal GLSL bits (sketches)

**Edge map & SDF (jump flood)**

```glsl
// Edge magnitude
float edgeMag(vec2 uv){
  vec3 s1 = texture(uTex, uv + vec2( 1, 0)/res).rgb - texture(uTex, uv - vec2(1,0)/res).rgb;
  vec3 s2 = texture(uTex, uv + vec2( 0, 1)/res).rgb - texture(uTex, uv - vec2(0,1)/res).rgb;
  return length(s1)+length(s2);
}
// Binarize & store positions; then run jump-flood to get SDF in a few passes
```

**Single-step block correlation (very coarse)**

```glsl
// in low-res pass (e.g., 64x64)
float ncc(vec2 uv, vec2 d){
  vec3 a = texture(A_low, uv).rgb;
  vec3 b = texture(B_low, uv + d).rgb;
  // cheap luminance
  float la = dot(a, vec3(0.2126,0.7152,0.0722));
  float lb = dot(b, vec3(0.2126,0.7152,0.0722));
  // zero-mean normalize approx with local blur pre-pass
  return 1.0 - abs(la - lb); // proxy similarity (fast)
}
// scan small offsets in [-1,1] pixels; pick argmax → coarse flow V0(uv)
```

**Advection (warp)**

```glsl
vec2 V = texture(uFlow, v_uv).xy;     // full-res flow
vec3 Aw = texture(uA, v_uv - t*V).rgb; // push A toward B
```

**Laplacian blend (per level)**

```glsl
vec3 L = mix(LA_warp, LB, t_level) * w_guided + LA_warp*(1.0 - w_guided);
```

**OKLab-ish interpolation (approx)**
(For production, use a LUT; here just the idea.)

```glsl
vec3 rgb2lin(vec3 c){ return pow(c, vec3(2.2)); }
vec3 lin2rgb(vec3 c){ return pow(c, vec3(1.0/2.2)); }
// Pretend OKLab via a 3D LUT texture uLUT; index by rgb
vec3 okA = texture(uRGB2OK, rgb2lin(Aw)).rgb;
vec3 okB = texture(uRGB2OK, rgb2lin(Bw)).rgb;
vec3 ok  = mix(okA, okB, t_color);
vec3 col = lin2rgb(texture(uOK2RGB, ok).rgb);
```

---

# Style presets (tasteful & magical)

* **“Dream Drift”**: Slow coarse morph (`t_coarse` eased), fast high-band interpolation, warm palette glide, subtle curl-noise only on highlights.
* **“Glassine”**: Edge-aligned warp is strong; colors interpolate late; add faint caustic-like RD glaze.
* **“Ink Bloom”**: Early high-band dissolve, late structure carry; temporal feedback higher in mid-tones; cool→warm palette cycle at the end.
* **“Aurora”**: Flow magnitude modulated by a low-freq sine; color manifold drift in OKLab a* channel for elegant hue travel.

---

# Performance tips

* Do **all** correlation on a tiny pyramid level; 1–2 refinement passes at ¼ res are enough.
* Prefer **half precision** (mediump) on mobile; avoid large kernels, rely on mips.
* Keep your **feedback** low (≤10%) to avoid trails but maintain coherence.
* Use **uniform buffers** for the easing curves and per-band weights; hot-swap presets without shader recompiles.

---

If you want, I can spin this into a working WebGL2 demo skeleton (HTML/JS + shaders) with:

* 4-level Laplacian blending,
* edge-guided flow,
* OKLab LUT interpolation,
* and two of the presets above.
